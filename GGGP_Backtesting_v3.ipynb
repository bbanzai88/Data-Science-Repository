{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbanzai88/Data-Science-Repository/blob/main/GGGP_Backtesting_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c725245e",
      "metadata": {
        "id": "c725245e"
      },
      "source": [
        "\n",
        "# GGGP ‚Äî Risk-Aware Trading Rule Discovery (\\$10,000 start + Portfolio)\n",
        "\n",
        "This notebook discovers **interpretable, rule-based strategies** using **Grammar-Guided Genetic Programming (GGGP)**, optimized by **risk-aware backtesting**.  \n",
        "It starts with **\\$10,000** capital, reports **final amount** and **drawdown ($ and %) per ticker**, and builds a **best portfolio** from the top strategies.\n",
        "\n",
        "**Pipeline**\n",
        "1. Load OHLCV CSVs from `/content/sample_data` (Colab) or `/mnt/data/stocks` (local).\n",
        "2. Compute indicators (SMA, EMA, RSI, MACD).\n",
        "3. Evolve boolean trading rules via GGGP.\n",
        "4. Backtest with costs and risk metrics (CAGR, MaxDD %, MaxDD $ , Calmar).\n",
        "5. Rank tickers in a **leaderboard** (with currency columns).\n",
        "6. Build an **equal-weight daily portfolio** from top-K strategies and evaluate.\n",
        "7. Export leaderboard and portfolio equity to `/mnt/data/gggp_exports/`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9yawKiEJ1FBf"
      },
      "id": "9yawKiEJ1FBf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kKsOtQG1TAL"
      },
      "source": [
        "0) Get S&P Data"
      ],
      "id": "7kKsOtQG1TAL"
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Robust S&P 500 downloader ‚Üí /content/sample_data/*.csv\n",
        "# - Tries Wikipedia with a real User-Agent\n",
        "# - Falls back to two GitHub mirrors if needed\n",
        "# - Normalizes Yahoo symbols (BRK.B -> BRK-B)\n",
        "# - Downloads in chunks with yfinance\n",
        "\n",
        "!pip -q install yfinance pandas lxml html5lib requests\n",
        "\n",
        "import requests, pandas as pd, yfinance as yf, time, math\n",
        "from pathlib import Path\n",
        "\n",
        "OUTDIR = Path(\"/content/sample_data\")\n",
        "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "PERIOD = \"10y\"         # \"5y\", \"10y\", \"max\"\n",
        "INTERVAL = \"1d\"        # \"1d\", \"1wk\", \"1mo\"\n",
        "CHUNK_SIZE = 50        # batch size for yfinance multi-download\n",
        "SLEEP_BETWEEN = 1.0    # seconds between chunks\n",
        "\n",
        "def get_sp500_tickers():\n",
        "    # 1) Wikipedia with headers\n",
        "    wiki_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "    headers = {\n",
        "        \"User-Agent\": (\n",
        "            \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \"\n",
        "            \"(KHTML, like Gecko) Chrome/120.0 Safari/537.36\"\n",
        "        )\n",
        "    }\n",
        "    try:\n",
        "        r = requests.get(wiki_url, headers=headers, timeout=20)\n",
        "        r.raise_for_status()\n",
        "        tables = pd.read_html(r.text)\n",
        "        df = tables[0]\n",
        "        # Find symbol column\n",
        "        sym_col = None\n",
        "        for c in df.columns:\n",
        "            if str(c).lower().strip() in {\"symbol\", \"ticker symbol\"}:\n",
        "                sym_col = c\n",
        "                break\n",
        "        if sym_col is None:\n",
        "            raise RuntimeError(\"Symbol column not found on Wikipedia table.\")\n",
        "        df = df.rename(columns={sym_col: \"Symbol\"})\n",
        "        tickers = df[\"Symbol\"].astype(str).str.strip().tolist()\n",
        "        if len(tickers) >= 450:  # sanity check\n",
        "            print(f\"‚úÖ Wikipedia returned {len(tickers)} symbols.\")\n",
        "            return tickers\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Wikipedia returned only {len(tickers)} rows, falling back‚Ä¶\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Wikipedia fetch failed: {type(e).__name__}: {e}\")\n",
        "\n",
        "    # 2) GitHub mirror #1 (datahub)\n",
        "    mirrors = [\n",
        "        \"https://raw.githubusercontent.com/datasets/s-and-p-500-companies/main/data/constituents.csv\",\n",
        "        \"https://raw.githubusercontent.com/datasets/s-and-p-500/master/data/constituents.csv\",\n",
        "    ]\n",
        "    for url in mirrors:\n",
        "        try:\n",
        "            df = pd.read_csv(url)\n",
        "            # Find col that looks like symbol\n",
        "            sym_col = None\n",
        "            for c in df.columns:\n",
        "                if str(c).lower().strip() in {\"symbol\", \"ticker\", \"ticker symbol\"}:\n",
        "                    sym_col = c\n",
        "                    break\n",
        "            if sym_col is None:\n",
        "                continue\n",
        "            tickers = df[sym_col].astype(str).str.strip().tolist()\n",
        "            if len(tickers) >= 450:\n",
        "                print(f\"‚úÖ Mirror worked: {url} ({len(tickers)} symbols)\")\n",
        "                return tickers\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Mirror failed {url}: {type(e).__name__}: {e}\")\n",
        "\n",
        "    raise RuntimeError(\"Could not retrieve S&P 500 tickers from any source.\")\n",
        "\n",
        "def normalize_for_yahoo(tickers):\n",
        "    # BRK.B -> BRK-B, BF.B -> BF-B, etc.\n",
        "    ysyms = [t.replace(\".\", \"-\").upper() for t in tickers if isinstance(t, str) and t.strip()]\n",
        "    # de-duplicate while preserving order\n",
        "    seen, out = set(), []\n",
        "    for t in ysyms:\n",
        "        if t not in seen:\n",
        "            seen.add(t)\n",
        "            out.append(t)\n",
        "    return out\n",
        "\n",
        "def save_ohlcv_csvs(ticker_list):\n",
        "    saved, failed = [], []\n",
        "    n = len(ticker_list)\n",
        "    n_chunks = math.ceil(n / CHUNK_SIZE)\n",
        "    for i in range(n_chunks):\n",
        "        chunk = ticker_list[i*CHUNK_SIZE:(i+1)*CHUNK_SIZE]\n",
        "        print(f\"\\nChunk {i+1}/{n_chunks}: downloading {len(chunk)} tickers‚Ä¶\")\n",
        "        try:\n",
        "            data = yf.download(\n",
        "                tickers=chunk,\n",
        "                period=PERIOD,\n",
        "                interval=INTERVAL,\n",
        "                group_by=\"ticker\",\n",
        "                auto_adjust=False,\n",
        "                threads=True,\n",
        "                progress=False,\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è yfinance chunk error: {e}\")\n",
        "            failed.extend(chunk)\n",
        "            time.sleep(SLEEP_BETWEEN)\n",
        "            continue\n",
        "\n",
        "        # Handle multiindex vs single-index frames\n",
        "        for t in chunk:\n",
        "            try:\n",
        "                if isinstance(data.columns, pd.MultiIndex):\n",
        "                    if t not in data.columns.get_level_values(0):\n",
        "                        failed.append(t)\n",
        "                        continue\n",
        "                    df_t = data[t].copy()\n",
        "                else:\n",
        "                    # extremely rare in chunk mode\n",
        "                    df_t = data.copy()\n",
        "\n",
        "                df_t = df_t.reset_index()\n",
        "                keep = [c for c in [\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"] if c in df_t.columns]\n",
        "                if \"Date\" not in keep or \"Close\" not in keep:\n",
        "                    failed.append(t); continue\n",
        "                df_t = df_t[keep].dropna(subset=[\"Close\"])\n",
        "                outpath = OUTDIR / f\"{t}.csv\"\n",
        "                df_t.to_csv(outpath, index=False)\n",
        "                saved.append(t)\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ö†Ô∏è Save failed {t}: {e}\")\n",
        "                failed.append(t)\n",
        "        time.sleep(SLEEP_BETWEEN)\n",
        "    return saved, failed\n",
        "\n",
        "tickers_raw = get_sp500_tickers()\n",
        "tickers = normalize_for_yahoo(tickers_raw)\n",
        "print(f\"\\nUsing {len(tickers)} Yahoo-normalized tickers (first 15): {tickers[:15]}\")\n",
        "\n",
        "saved, failed = save_ohlcv_csvs(tickers)\n",
        "print(f\"\\n‚úÖ Saved {len(saved)} tickers to {OUTDIR}\")\n",
        "if failed:\n",
        "    print(f\"‚ö†Ô∏è Failed ({len(failed)}): {failed[:25]}{'...' if len(failed)>25 else ''}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "7nE1hgxlDoZ-"
      },
      "execution_count": null,
      "outputs": [],
      "id": "7nE1hgxlDoZ-"
    },
    {
      "cell_type": "markdown",
      "id": "b8e20826",
      "metadata": {
        "id": "b8e20826"
      },
      "source": [
        "## 1) Setup & Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18ba9cb6",
      "metadata": {
        "id": "18ba9cb6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os, glob, math, json, random, traceback\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, Tuple, List\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 100)\n",
        "\n",
        "# Detect CSV directory\n",
        "CAND_DIRS = [Path(\"/content/sample_data\"), Path(\"/mnt/data/stocks\")]\n",
        "DATA_DIR = None\n",
        "for d in CAND_DIRS:\n",
        "    if d.exists() and any(Path(p).suffix.lower()==\".csv\" for p in glob.glob(str(d/\"*.csv\"))):\n",
        "        DATA_DIR = d; break\n",
        "if DATA_DIR is None:\n",
        "    DATA_DIR = CAND_DIRS[0]\n",
        "print(\"üìÅ Using data directory:\", DATA_DIR)\n",
        "\n",
        "START_CAPITAL = 10_000.0  # USD\n",
        "PERIODS_PER_YEAR = 252\n",
        "\n",
        "def load_ohlcv_csv(path: Path) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path)\n",
        "    rename = {}\n",
        "    for need in [\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]:\n",
        "        found = None\n",
        "        for c in df.columns:\n",
        "            if c.lower()==need.lower():\n",
        "                found=c; break\n",
        "        if not found:\n",
        "            raise ValueError(f\"Missing column {need} in {path.name}\")\n",
        "        rename[found]=need\n",
        "    df = df.rename(columns=rename)\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "    df = df.sort_values(\"Date\").reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "# Load frames\n",
        "frames: Dict[str, pd.DataFrame] = {}\n",
        "for p in sorted(glob.glob(str(DATA_DIR/\"*.csv\"))):\n",
        "    t = Path(p).stem.upper()\n",
        "    try:\n",
        "        df = load_ohlcv_csv(Path(p))\n",
        "        if len(df) < 200:\n",
        "            print(f\"‚ö†Ô∏è {t}: too few rows ({len(df)}) ‚Äî skipping\")\n",
        "            continue\n",
        "        frames[t] = df\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Skipping {Path(p).name}: {e}\")\n",
        "\n",
        "tickers = sorted(frames.keys())\n",
        "print(f\"‚úÖ Loaded {len(tickers)} tickers:\", tickers[:20])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15a77e3b",
      "metadata": {
        "id": "15a77e3b"
      },
      "source": [
        "## 2) Indicators & Backtesting (currency-aware)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb15edec",
      "metadata": {
        "id": "fb15edec"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Indicators ---\n",
        "def ema(series: pd.Series, span: int) -> pd.Series:\n",
        "    return series.ewm(span=span, adjust=False).mean()\n",
        "\n",
        "def sma(series: pd.Series, window: int) -> pd.Series:\n",
        "    return series.rolling(window=window, min_periods=window).mean()\n",
        "\n",
        "def rsi(close: pd.Series, period: int = 14) -> pd.Series:\n",
        "    delta = close.diff()\n",
        "    up = np.where(delta > 0, delta, 0.0)\n",
        "    down = np.where(delta < 0, -delta, 0.0)\n",
        "    roll_up = pd.Series(up, index=close.index).rolling(period).mean()\n",
        "    roll_down = pd.Series(down, index=close.index).rolling(period).mean()\n",
        "    rs = roll_up / (roll_down + 1e-12)\n",
        "    return 100 - (100 / (1 + rs))\n",
        "\n",
        "def macd(close: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):\n",
        "    macd_line = ema(close, fast) - ema(close, slow)\n",
        "    signal_line = ema(macd_line, signal)\n",
        "    return macd_line, signal_line\n",
        "\n",
        "def max_drawdown_amount(equity: pd.Series):\n",
        "    \"\"\"Returns (dd_pct negative, dd_amount negative).\"\"\"\n",
        "    peak = equity.cummax()\n",
        "    dd_amt = equity - peak\n",
        "    dd_pct = dd_amt / (peak + 1e-12)\n",
        "    return float(dd_pct.min()), float(dd_amt.min())\n",
        "\n",
        "def cagr_from_equity(equity: pd.Series, periods_per_year: int = 252) -> float:\n",
        "    if len(equity) < 2:\n",
        "        return 0.0\n",
        "    total = equity.iloc[-1] / equity.iloc[0] - 1.0\n",
        "    years = max(len(equity)/periods_per_year, 1e-9)\n",
        "    return (1 + total) ** (1/years) - 1\n",
        "\n",
        "def simple_backtest(df: pd.DataFrame, signal: pd.Series, fee_bps: float = 5.0, slippage_bps: float = 0.0,\n",
        "                    start_capital: float = 10_000.0, return_daily: bool = False):\n",
        "    \"\"\"Long/flat. Position=1 when signal True else 0. Costs on position changes.\"\"\"\n",
        "    close = df[\"Close\"].astype(float)\n",
        "    fee = fee_bps / 1e4\n",
        "    slip = slippage_bps / 1e4\n",
        "\n",
        "    pos = signal.astype(int).clip(0,1)\n",
        "    pos_shift = pos.shift(1).fillna(0)\n",
        "    trades = (pos != pos_shift).astype(int)\n",
        "\n",
        "    daily_ret = close.pct_change().fillna(0.0)\n",
        "    strat_ret = pos.shift(1).fillna(0) * daily_ret\n",
        "\n",
        "    # costs on flip days\n",
        "    cost = trades * (fee + slip)\n",
        "    strat_ret -= cost\n",
        "\n",
        "    equity = (1 + strat_ret).cumprod() * float(start_capital)\n",
        "\n",
        "    dd_pct, dd_amt = max_drawdown_amount(equity)\n",
        "    annual = cagr_from_equity(equity)\n",
        "\n",
        "    calmar = annual / (abs(dd_pct) + 1e-9) if dd_pct < 0 else (float(\"inf\") if annual > 0 else 0.0)\n",
        "\n",
        "    return {\n",
        "        \"equity\": equity,\n",
        "        \"final_amount\": float(equity.iloc[-1]),\n",
        "        \"total_return_pct\": float(equity.iloc[-1]/equity.iloc[0]-1.0),\n",
        "        \"cagr\": float(annual),\n",
        "        \"max_dd_pct\": float(dd_pct),\n",
        "        \"max_dd_amount\": float(dd_amt),\n",
        "        \"calmar\": float(calmar),\n",
        "        \"trades\": int(trades.sum()),\n",
        "        \"daily_ret\": strat_ret if return_daily else None,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "316f21af",
      "metadata": {
        "id": "316f21af"
      },
      "source": [
        "## 3) Grammar, Genome, and Rule Decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75a79a52",
      "metadata": {
        "id": "75a79a52"
      },
      "outputs": [],
      "source": [
        "\n",
        "from dataclasses import dataclass\n",
        "\n",
        "INDICATOR_FAMILIES = [\n",
        "    (\"CLOSE\", {}),\n",
        "    (\"SMA\",   {\"n\": [5,10,20,50,100,200]}),\n",
        "    (\"EMA\",   {\"n\": [5,10,20,50,100,200]}),\n",
        "    (\"RSI\",   {\"n\": [7,14,21,28]}),\n",
        "    (\"MACD_LINE\", {\"fast\":[8,12], \"slow\":[17,26], \"signal\":[9]}),\n",
        "    (\"MACD_SIGNAL\", {\"fast\":[8,12], \"slow\":[17,26], \"signal\":[9]}),\n",
        "]\n",
        "OPS = [\">\",\"<\"]\n",
        "LOGICS = [\"AND\",\"OR\"]\n",
        "MAX_CLAUSES = 3\n",
        "\n",
        "@dataclass\n",
        "class Clause:\n",
        "    left: tuple\n",
        "    op: str\n",
        "    right: tuple\n",
        "\n",
        "@dataclass\n",
        "class Rule:\n",
        "    clauses: list\n",
        "    joins: list\n",
        "\n",
        "def random_indicator():\n",
        "    fam, cfg = random.choice(INDICATOR_FAMILIES)\n",
        "    params = {k: random.choice(v) for k, v in cfg.items()}\n",
        "    return fam, params\n",
        "\n",
        "def mutate_indicator(ind):\n",
        "    fam, cfg = ind\n",
        "    if random.random() < 0.3:\n",
        "        return random_indicator()\n",
        "    fam_def = next(x for x in INDICATOR_FAMILIES if x[0]==fam)\n",
        "    _, pdef = fam_def\n",
        "    new_params = dict(cfg)\n",
        "    for k, choices in pdef.items():\n",
        "        if random.random()<0.5:\n",
        "            new_params[k] = random.choice(choices)\n",
        "    return fam, new_params\n",
        "\n",
        "def random_clause():\n",
        "    return Clause(random_indicator(), random.choice(OPS), random_indicator())\n",
        "\n",
        "def mutate_clause(cl: Clause) -> Clause:\n",
        "    lft = mutate_indicator(cl.left) if random.random()<0.5 else cl.left\n",
        "    rgt = mutate_indicator(cl.right) if random.random()<0.5 else cl.right\n",
        "    op  = random.choice(OPS) if random.random()<0.2 else cl.op\n",
        "    return Clause(lft, op, rgt)\n",
        "\n",
        "def random_rule():\n",
        "    k = random.randint(1, MAX_CLAUSES)\n",
        "    cls = [random_clause() for _ in range(k)]\n",
        "    jns = [random.choice(LOGICS) for _ in range(k-1)]\n",
        "    return Rule(cls, jns)\n",
        "\n",
        "def mutate_rule(rule: Rule, p_add=0.2, p_del=0.2) -> Rule:\n",
        "    clauses = list(rule.clauses)\n",
        "    joins = list(rule.joins)\n",
        "\n",
        "    # mutate a random clause\n",
        "    i = random.randrange(len(clauses))\n",
        "    clauses[i] = mutate_clause(clauses[i])\n",
        "\n",
        "    # maybe add a clause\n",
        "    if len(clauses) < MAX_CLAUSES and random.random() < p_add:\n",
        "        clauses.append(random_clause())\n",
        "        if len(clauses) > 1:\n",
        "            joins.append(random.choice(LOGICS))\n",
        "\n",
        "    # maybe delete a clause\n",
        "    if len(clauses) > 1 and random.random() < p_del:\n",
        "        j = random.randrange(len(clauses))\n",
        "        clauses.pop(j)\n",
        "        if len(joins) >= 1:\n",
        "            joins.pop(0 if j==0 else j-1)\n",
        "\n",
        "    # tweak joins\n",
        "    joins = [random.choice(LOGICS) if random.random()<0.2 else j for j in joins]\n",
        "\n",
        "    return Rule(clauses=clauses, joins=joins)\n",
        "\n",
        "def crossover_rule(a: Rule, b: Rule):\n",
        "    if len(a.clauses)==1 and len(b.clauses)==1:\n",
        "        ca, cb = a.clauses[0], b.clauses[0]\n",
        "        if random.random()<0.5:\n",
        "            ca2 = Clause(cb.left, ca.op, ca.right)\n",
        "            cb2 = Clause(ca.left, cb.op, cb.right)\n",
        "        else:\n",
        "            ca2 = Clause(ca.left, ca.op, cb.right)\n",
        "            cb2 = Clause(cb.left, cb.op, ca.right)\n",
        "        return Rule([ca2],[]), Rule([cb2],[])\n",
        "    cut_a = random.randrange(1, len(a.clauses)+1)\n",
        "    cut_b = random.randrange(1, len(b.clauses)+1)\n",
        "    na = a.clauses[:cut_a] + b.clauses[cut_b:]\n",
        "    nb = b.clauses[:cut_b] + a.clauses[cut_a:]\n",
        "    def rebuild(cls):\n",
        "        return [] if len(cls)<=1 else [random.choice(LOGICS) for _ in range(len(cls)-1)]\n",
        "    return Rule(na, rebuild(na)), Rule(nb, rebuild(nb))\n",
        "\n",
        "def indicator_series(family: str, params: dict, df: pd.DataFrame) -> pd.Series:\n",
        "    c = df[\"Close\"].astype(float)\n",
        "    if family==\"CLOSE\": return c\n",
        "    if family==\"SMA\":   return sma(c, params[\"n\"])\n",
        "    if family==\"EMA\":   return ema(c, params[\"n\"])\n",
        "    if family==\"RSI\":   return rsi(c, params[\"n\"])\n",
        "    if family in (\"MACD_LINE\",\"MACD_SIGNAL\"):\n",
        "        m, s = macd(c, params[\"fast\"], params[\"slow\"], params[\"signal\"])\n",
        "        return m if family==\"MACD_LINE\" else s\n",
        "    raise ValueError(f\"Unknown family {family}\")\n",
        "\n",
        "def rule_to_signal(rule: Rule, df: pd.DataFrame) -> pd.Series:\n",
        "    masks = []\n",
        "    for cl in rule.clauses:\n",
        "        L = indicator_series(cl.left[0], cl.left[1], df)\n",
        "        R = indicator_series(cl.right[0], cl.right[1], df)\n",
        "        m = (L > R) if cl.op == \">\" else (L < R)\n",
        "        masks.append(m.fillna(False))\n",
        "    if not masks:\n",
        "        return pd.Series(False, index=df.index)\n",
        "    res = masks[0]\n",
        "    for op, m in zip(rule.joins, masks[1:]):\n",
        "        res = (res & m) if op==\"AND\" else (res | m)\n",
        "    return res.fillna(False)\n",
        "\n",
        "def rule_to_string(rule: Rule) -> str:\n",
        "    parts = []\n",
        "    for i, cl in enumerate(rule.clauses):\n",
        "        def ind_str(ind): fam, p = ind; return f\"{fam}{p}\" if p else fam\n",
        "        parts.append(f\"({ind_str(cl.left)} {cl.op} {ind_str(cl.right)})\")\n",
        "        if i < len(rule.joins): parts.append(f\" {rule.joins[i]} \")\n",
        "    return \"\".join(parts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6393927",
      "metadata": {
        "id": "c6393927"
      },
      "source": [
        "## 4) GA Training / Evaluation (risk-aware fitness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b9ab8b6",
      "metadata": {
        "id": "6b9ab8b6"
      },
      "outputs": [],
      "source": [
        "\n",
        "@dataclass\n",
        "class GAConfig:\n",
        "    pop_size: int = 60\n",
        "    gens: int = 25\n",
        "    tourn_k: int = 3\n",
        "    cx_prob: float = 0.7\n",
        "    mut_prob: float = 0.5\n",
        "    seed: int = 42\n",
        "    fee_bps: float = 5.0\n",
        "    slippage_bps: float = 0.0\n",
        "    fitness_lambda_dd: float = 2.0\n",
        "    train_frac: float = 0.7\n",
        "\n",
        "def fitness(rule: Rule, df: pd.DataFrame, cfg: GAConfig):\n",
        "    sig = rule_to_signal(rule, df)\n",
        "    res = simple_backtest(df, sig, cfg.fee_bps, cfg.slippage_bps, start_capital=START_CAPITAL)\n",
        "    # Risk-aware fitness: CAGR - lambda * |max_dd_pct|\n",
        "    score = res[\"cagr\"] - cfg.fitness_lambda_dd * abs(res[\"max_dd_pct\"])\n",
        "    return score, res\n",
        "\n",
        "def train_ga_on_stock(df: pd.DataFrame, cfg: GAConfig):\n",
        "    n = len(df)\n",
        "    split = int(n * cfg.train_frac)\n",
        "    train = df.iloc[:split].copy()\n",
        "    test  = df.iloc[split:].copy()\n",
        "\n",
        "    random.seed(cfg.seed)\n",
        "    pop = [random_rule() for _ in range(cfg.pop_size)]\n",
        "\n",
        "    def tournament():\n",
        "        cand = random.sample(pop, cfg.tourn_k)\n",
        "        scored = [(fitness(r, train, cfg)[0], r) for r in cand]\n",
        "        return max(scored, key=lambda x:x[0])[1]\n",
        "\n",
        "    best_rule, best_score = None, -1e9\n",
        "    history = []\n",
        "    for g in range(cfg.gens):\n",
        "        # evaluate\n",
        "        for r in pop:\n",
        "            s, _ = fitness(r, train, cfg)\n",
        "            if s > best_score:\n",
        "                best_rule, best_score = r, s\n",
        "        history.append(best_score)\n",
        "\n",
        "        # next generation\n",
        "        new_pop = []\n",
        "        while len(new_pop) < cfg.pop_size:\n",
        "            if random.random() < cfg.cx_prob:\n",
        "                p1, p2 = tournament(), tournament()\n",
        "                c1, c2 = crossover_rule(p1, p2)\n",
        "                if random.random() < cfg.mut_prob: c1 = mutate_rule(c1)\n",
        "                if random.random() < cfg.mut_prob: c2 = mutate_rule(c2)\n",
        "                new_pop.extend([c1, c2])\n",
        "            else:\n",
        "                p = tournament()\n",
        "                c = mutate_rule(p) if random.random()<cfg.mut_prob else p\n",
        "                new_pop.append(c)\n",
        "        pop = new_pop[:cfg.pop_size]\n",
        "\n",
        "    # Evaluate best on both sets (with daily returns for portfolio)\n",
        "    train_sig = rule_to_signal(best_rule, train)\n",
        "    test_sig  = rule_to_signal(best_rule,  test)\n",
        "    train_res = simple_backtest(train, train_sig, cfg.fee_bps, cfg.slippage_bps, START_CAPITAL, return_daily=True)\n",
        "    test_res  = simple_backtest(test,  test_sig,  cfg.fee_bps, cfg.slippage_bps, START_CAPITAL, return_daily=True)\n",
        "\n",
        "    return {\n",
        "        \"best_rule\": best_rule,\n",
        "        \"best_rule_str\": rule_to_string(best_rule),\n",
        "        \"train_metrics\": train_res,\n",
        "        \"test_metrics\": test_res,\n",
        "        \"split_idx\": split,\n",
        "        \"history\": history,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f05c8a0",
      "metadata": {
        "id": "0f05c8a0"
      },
      "source": [
        "## 5) Run Evolution Across Tickers + Leaderboard (with $ columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58d778bf",
      "metadata": {
        "id": "58d778bf"
      },
      "outputs": [],
      "source": [
        "\n",
        "cfg = GAConfig()\n",
        "\n",
        "results = []\n",
        "per_ticker = {}\n",
        "\n",
        "for t in tickers:\n",
        "    print(f\"=== {t} ===\")\n",
        "    try:\n",
        "        out = train_ga_on_stock(frames[t], cfg)\n",
        "        per_ticker[t] = out\n",
        "        tm = out[\"test_metrics\"]\n",
        "        results.append({\n",
        "            \"ticker\": t,\n",
        "            \"rule\": out[\"best_rule_str\"],\n",
        "            \"test_final_amount\": tm[\"final_amount\"],\n",
        "            \"test_total_return_pct\": tm[\"total_return_pct\"],\n",
        "            \"test_cagr\": tm[\"cagr\"],\n",
        "            \"test_max_dd_pct\": tm[\"max_dd_pct\"],\n",
        "            \"test_max_dd_amount\": tm[\"max_dd_amount\"],\n",
        "            \"test_calmar\": tm[\"calmar\"],\n",
        "            \"test_trades\": tm[\"trades\"],\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ö†Ô∏è {t} failed: {e}\")\n",
        "\n",
        "leaderboard = pd.DataFrame(results).sort_values(\n",
        "    [\"test_calmar\",\"test_cagr\",\"test_final_amount\"], ascending=[False, False, False]\n",
        ").reset_index(drop=True)\n",
        "\n",
        "leaderboard.head(20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e458334",
      "metadata": {
        "id": "4e458334"
      },
      "source": [
        "## 6) Plot Top Strategy Equity (currency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52c2dda9",
      "metadata": {
        "id": "52c2dda9"
      },
      "outputs": [],
      "source": [
        "\n",
        "if len(leaderboard) > 0:\n",
        "    t = leaderboard.iloc[0][\"ticker\"]\n",
        "    out = per_ticker[t]\n",
        "    split = out[\"split_idx\"]\n",
        "    df = frames[t]\n",
        "    rule = out[\"best_rule\"]\n",
        "    sig = rule_to_signal(rule, df)\n",
        "    res = simple_backtest(df, sig, cfg.fee_bps, cfg.slippage_bps, START_CAPITAL)\n",
        "\n",
        "    print(f\"üèÜ Top: {t}\")\n",
        "    print(\"Rule:\", out[\"best_rule_str\"])\n",
        "    print(f\"Final = ${res['final_amount']:,.2f} | MaxDD = {res['max_dd_pct']:.2%} ({res['max_dd_amount']:,.0f}) | CAGR = {res['cagr']:.2%} | Calmar = {res['calmar']:.2f}\")\n",
        "\n",
        "    eq = res[\"equity\"]\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.plot(df[\"Date\"], eq.values)\n",
        "    plt.axvline(df[\"Date\"].iloc[split], linestyle=\"--\")\n",
        "    plt.title(f\"Equity ‚Äî {t}\")\n",
        "    plt.xlabel(\"Date\"); plt.ylabel(\"Equity ($)\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No leaderboard results.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e49f8d86",
      "metadata": {
        "id": "e49f8d86"
      },
      "source": [
        "## 7) Build **Best Portfolio** (equal-weight daily over Top-K)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc727c4a",
      "metadata": {
        "id": "fc727c4a"
      },
      "outputs": [],
      "source": [
        "\n",
        "TOP_K = min(10, len(leaderboard))  # change as desired\n",
        "selected = leaderboard.head(TOP_K)[\"ticker\"].tolist()\n",
        "print(f\"üß∫ Portfolio members ({len(selected)}):\", selected)\n",
        "\n",
        "def build_member_daily_returns(ticker: str, out_obj: dict, df_full: pd.DataFrame):\n",
        "    \"\"\"Recompute full-period daily returns for the evolved rule on full data (train+test).\"\"\"\n",
        "    rule = out_obj[\"best_rule\"]\n",
        "    sig = rule_to_signal(rule, df_full)\n",
        "    bt = simple_backtest(df_full, sig, cfg.fee_bps, cfg.slippage_bps, START_CAPITAL, return_daily=True)\n",
        "    ret = bt[\"daily_ret\"].rename(ticker)\n",
        "    ret.index = df_full[\"Date\"]\n",
        "    return ret\n",
        "\n",
        "if selected:\n",
        "    rets = []\n",
        "    for t in selected:\n",
        "        r = build_member_daily_returns(t, per_ticker[t], frames[t])\n",
        "        rets.append(r)\n",
        "\n",
        "    R = pd.concat(rets, axis=1).sort_index()\n",
        "    port_ret = R.mean(axis=1, skipna=True).fillna(0.0)\n",
        "    port_equity = (1 + port_ret).cumprod() * START_CAPITAL\n",
        "\n",
        "    # Portfolio metrics\n",
        "    def max_dd_amt(e):\n",
        "        peak = e.cummax(); dd_amt = e - peak; dd_pct = dd_amt/peak\n",
        "        return float(dd_pct.min()), float(dd_amt.min())\n",
        "    ddp, dda = max_dd_amt(port_equity)\n",
        "    years = max(len(port_equity)/252, 1e-9)\n",
        "    total = port_equity.iloc[-1]/port_equity.iloc[0]-1\n",
        "    cagr_port = (1+total)**(1/years)-1\n",
        "    calmar_port = cagr_port / (abs(ddp)+1e-9) if ddp<0 else (float(\"inf\") if cagr_port>0 else 0.0)\n",
        "\n",
        "    print(f\"üìà Portfolio (Top {len(selected)}): Final=${port_equity.iloc[-1]:,.2f} | MaxDD={ddp:.2%} ({dda:,.0f}) | CAGR={cagr_port:.2%} | Calmar={calmar_port:.2f}\")\n",
        "\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.plot(port_equity.index, port_equity.values)\n",
        "    plt.title(f\"Best Portfolio ‚Äî Top {len(selected)} by Calmar\")\n",
        "    plt.xlabel(\"Date\"); plt.ylabel(\"Equity ($)\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No members selected for portfolio.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ab81e04",
      "metadata": {
        "id": "3ab81e04"
      },
      "source": [
        "## 8) Export artifacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3685770e",
      "metadata": {
        "id": "3685770e"
      },
      "outputs": [],
      "source": [
        "\n",
        "OUT_DIR = Path(\"/mnt/data/gggp_exports\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if 'leaderboard' in globals() and len(leaderboard)>0:\n",
        "    lb_path = OUT_DIR / \"leaderboard_with_currency.csv\"\n",
        "    leaderboard.to_csv(lb_path, index=False)\n",
        "    print(\"üíæ Saved leaderboard:\", lb_path)\n",
        "\n",
        "    try:\n",
        "        port_df = pd.DataFrame({\"Date\": port_equity.index, \"Equity\": port_equity.values})\n",
        "        port_path = OUT_DIR / \"best_portfolio_equity.csv\"\n",
        "        port_df.to_csv(port_path, index=False)\n",
        "        print(\"üíæ Saved best portfolio equity:\", port_path)\n",
        "    except NameError:\n",
        "        print(\"‚ÑπÔ∏è Portfolio not built (skipping save).\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è No leaderboard to export.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}